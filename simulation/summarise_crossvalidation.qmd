---
title: Crossvalidation summary
jupyter: python3
---

```{python}
#| tags: [parameters]
# default values; change these here or like
# quarto render summarise_crossvalidation.qmd -P basename:x/y/z
basename = "density_saddle/out_123_stats/rep975917"
```

```{python}
import os, sys, pickle, glob
import numpy as np
import pandas as pd
import product_fem as pf
import fenics
import json
import matplotlib.pyplot as plt
import matplotlib.tri as tri
```

```{python}
all_xdirs = glob.glob(f"{basename}_xval_*")
result_files = glob.glob(f"{basename}_xval_*/results.pkl")
print(f"Reporting on the {len(result_files)} directories of the form {basename}_xval_* having a results.pkl file.")
if len(result_files) < len(all_xdirs):
    print(f"({len(all_xdirs) - len(result_files)} such directories do not have the result file)")
assert len(result_files) > 0, f"None of the {len(all_xdirs)} directories of the form {basename}_xval_* have a results.pkl file."
```

```{python}
configs = {}
results = {}
for x in all_xdirs:
    jf = os.path.join(x, "xval_params.json")
    rf = os.path.join(x, "results.pkl")
    if os.path.isfile(jf) and os.path.isfile(rf):
        with open(jf, 'r') as f:
            configs[x] = json.load(f)
        with open(rf, 'rb') as f:
            results[x] = pickle.load(f)
xdirs = [x for x in all_xdirs if x in results]
```

```{python}
df = pd.DataFrame({
    "dir" : xdirs,
    "l2": [results[x]["params"]["regularization"]["l2"][0] for x in xdirs],
    "smoothing": [results[x]["params"]["regularization"]["smoothing"][0] for x in xdirs],
    "test_error": [np.mean([results[x][j]["test_error"] for j in range(configs[x]['folds']) if j in results[x]]) for x in xdirs],
}).set_index("dir")
for k in ['l2err', 'l2reg', 'smreg']:
    df[k] = [np.mean([results[x][j]["losses"][k][-1] for j in range(configs[x]['folds']) if j in results[x]]) for x in xdirs]
```

Here is the range of crossvalidation parameters considered (left)
and test error plotted against each of these parameters, marginally (right).

```{python}
fig, axes = plt.subplots(1, 3, figsize=(12, 4))
for ax, (j, k) in zip(axes, (('l2', 'smoothing'), ("l2", "test_error"), ("smoothing", "test_error"))):
    ax.scatter(df[j], df[k])
    ax.set_xlabel(j)
    ax.set_ylabel(k)

plt.tight_layout()
```

And, here is how various things are distributed across the range of values.
Here **test error** is the out-of-sample test error from crossvalidation;
the remaining three plots are of the three components of loss,
which are **training error**, an **L2 penalty** and a **smoothing penalty** (which is just the L2 norm of the gradient).

```{python}
def irreg_heatmap(x, y, z, ax, label="", vmin=None, vmax=None, colorbar=True):
    ax.tricontour(x.to_numpy(), y.to_numpy(), z.to_numpy(),
        levels=12, linewidths=0.5, colors='k', vmin=vmin, vmax=vmax)
    cntr = ax.tricontourf(x, y, z, levels=12, cmap="RdBu_r", vmin=vmin, vmax=vmax)
    ax.plot(x, y, 'ko')
    if colorbar:
        fig.colorbar(cntr, ax=ax, label=label)

def plot_errors(df, **kwargs):
    for k, (a, b) in kwargs.items():
        ut = np.logical_and(df[k] >= a, df[k] <= b)
        df = df.loc[ut, :]
    assert df.shape[0] > 0, f"No matching rows for {kwargs}"
    fig, axes = plt.subplots(2, 2, figsize=(10, 8))
    labels = [('test_error', "test error"), ('l2err', "training error"), ('l2reg', "l2 penalty"), ('smreg', "smoothing penalty")]
    vmax = max([np.max(df[k]) for k, j in labels])
    for (k, lk), ax in zip(labels, axes.flatten()):
        irreg_heatmap(df['l2'], df['smoothing'], df[k], ax, label=lk, vmin=0, vmax=vmax)
        ax.set_xlabel("l2 regularization"); ax.set_ylabel("smoothing regularization")
        ax.set_title(lk)
    fig.tight_layout()
    return axes
```

## First grid

```{python}
plot_errors(df);
```

## Zooming in

Next we could zoom in on small values of the l2 regularization parameter:

```{python}
# plot_errors(df, l2=(0, 100));
```
